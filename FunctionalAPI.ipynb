{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data=load_iris()\n",
    "X=data[\"data\"]\n",
    "y=data[\"target\"].reshape(150,1)\n",
    "# y = keras.utils.to_categorical(y, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/trantorchd.com/paritosh.yadav/anaconda3/envs/deeplearning/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/50\n",
      "120/120 [==============================] - 0s 2ms/step - loss: 1.7421 - accuracy: 0.4167 - val_loss: 5.2826 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 0s 162us/step - loss: 1.4611 - accuracy: 0.4167 - val_loss: 4.7454 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 0s 146us/step - loss: 1.3140 - accuracy: 0.4167 - val_loss: 4.3392 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 0s 128us/step - loss: 1.2073 - accuracy: 0.4167 - val_loss: 3.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 0s 159us/step - loss: 1.1215 - accuracy: 0.4500 - val_loss: 3.5364 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 0s 185us/step - loss: 1.0532 - accuracy: 0.7583 - val_loss: 3.1626 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 0s 133us/step - loss: 0.9861 - accuracy: 0.8083 - val_loss: 2.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 0s 131us/step - loss: 0.9292 - accuracy: 0.8333 - val_loss: 2.5544 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 0s 165us/step - loss: 0.8867 - accuracy: 0.8333 - val_loss: 2.3079 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 0s 150us/step - loss: 0.8421 - accuracy: 0.8333 - val_loss: 2.0647 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 0s 129us/step - loss: 0.8077 - accuracy: 0.8333 - val_loss: 1.9887 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 0s 170us/step - loss: 0.7753 - accuracy: 0.8333 - val_loss: 1.8114 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 0s 117us/step - loss: 0.7439 - accuracy: 0.8333 - val_loss: 1.6575 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 0s 129us/step - loss: 0.7175 - accuracy: 0.8333 - val_loss: 1.5435 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 0s 160us/step - loss: 0.6931 - accuracy: 0.8333 - val_loss: 1.4256 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 0s 149us/step - loss: 0.6680 - accuracy: 0.8333 - val_loss: 1.3940 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 0s 143us/step - loss: 0.6449 - accuracy: 0.8333 - val_loss: 1.3759 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 0s 130us/step - loss: 0.6207 - accuracy: 0.8333 - val_loss: 1.3404 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 0s 160us/step - loss: 0.5989 - accuracy: 0.8333 - val_loss: 1.3739 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 0s 132us/step - loss: 0.5795 - accuracy: 0.8333 - val_loss: 1.2335 - val_accuracy: 0.0333\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 0s 158us/step - loss: 0.5574 - accuracy: 0.8333 - val_loss: 1.2327 - val_accuracy: 0.0333\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 0s 145us/step - loss: 0.5381 - accuracy: 0.8417 - val_loss: 1.2685 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 0s 207us/step - loss: 0.5225 - accuracy: 0.8333 - val_loss: 1.1726 - val_accuracy: 0.0333\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 0s 137us/step - loss: 0.5029 - accuracy: 0.8417 - val_loss: 1.1736 - val_accuracy: 0.0333\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 0s 152us/step - loss: 0.4877 - accuracy: 0.8417 - val_loss: 1.2272 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 0s 159us/step - loss: 0.4691 - accuracy: 0.8333 - val_loss: 1.1010 - val_accuracy: 0.0667\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 0s 176us/step - loss: 0.4551 - accuracy: 0.8500 - val_loss: 1.1737 - val_accuracy: 0.0333\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 0s 172us/step - loss: 0.4437 - accuracy: 0.8417 - val_loss: 1.0858 - val_accuracy: 0.0667\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 0s 160us/step - loss: 0.4320 - accuracy: 0.8333 - val_loss: 1.0496 - val_accuracy: 0.0667\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 0s 173us/step - loss: 0.4186 - accuracy: 0.8500 - val_loss: 0.9903 - val_accuracy: 0.0667\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 0s 150us/step - loss: 0.4024 - accuracy: 0.8750 - val_loss: 1.0741 - val_accuracy: 0.0667\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 0s 187us/step - loss: 0.3945 - accuracy: 0.8417 - val_loss: 0.9730 - val_accuracy: 0.0667\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 0s 139us/step - loss: 0.3852 - accuracy: 0.8750 - val_loss: 1.0534 - val_accuracy: 0.0667\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 0s 142us/step - loss: 0.3754 - accuracy: 0.8417 - val_loss: 0.9938 - val_accuracy: 0.0667\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 0s 181us/step - loss: 0.3638 - accuracy: 0.8667 - val_loss: 0.9910 - val_accuracy: 0.0667\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 0s 177us/step - loss: 0.3540 - accuracy: 0.8583 - val_loss: 0.9235 - val_accuracy: 0.1333\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 0s 183us/step - loss: 0.3463 - accuracy: 0.8750 - val_loss: 0.8572 - val_accuracy: 0.2000\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 0s 181us/step - loss: 0.3401 - accuracy: 0.9083 - val_loss: 1.0165 - val_accuracy: 0.0667\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 0s 188us/step - loss: 0.3330 - accuracy: 0.8750 - val_loss: 0.9837 - val_accuracy: 0.0667\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 0s 165us/step - loss: 0.3219 - accuracy: 0.8750 - val_loss: 0.9156 - val_accuracy: 0.1333\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 0s 173us/step - loss: 0.3170 - accuracy: 0.9000 - val_loss: 0.9632 - val_accuracy: 0.0667\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 0s 159us/step - loss: 0.3101 - accuracy: 0.8917 - val_loss: 0.9848 - val_accuracy: 0.0667\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 0s 118us/step - loss: 0.3046 - accuracy: 0.8833 - val_loss: 0.9387 - val_accuracy: 0.1333\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 0s 122us/step - loss: 0.2959 - accuracy: 0.9000 - val_loss: 0.9114 - val_accuracy: 0.1333\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 0s 141us/step - loss: 0.2954 - accuracy: 0.8667 - val_loss: 0.7937 - val_accuracy: 0.3000\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 0s 163us/step - loss: 0.2857 - accuracy: 0.9250 - val_loss: 0.9546 - val_accuracy: 0.1000\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 0s 184us/step - loss: 0.2848 - accuracy: 0.8667 - val_loss: 0.8215 - val_accuracy: 0.2333\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 0s 159us/step - loss: 0.2775 - accuracy: 0.9000 - val_loss: 0.8075 - val_accuracy: 0.2333\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 0s 166us/step - loss: 0.2818 - accuracy: 0.8917 - val_loss: 0.8165 - val_accuracy: 0.2333\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 0s 148us/step - loss: 0.2676 - accuracy: 0.9417 - val_loss: 0.9098 - val_accuracy: 0.1333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff8763b05c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(4,))\n",
    "output_1 = Dense(8,activation='relu')(inputs)\n",
    "output_2 = Dense(16,activation='relu')(output_1)\n",
    "prediction = Dense(3,activation='softmax')(output_2)\n",
    "model = Model(input=inputs, outputs = prediction)\n",
    "model.compile(optimizer = 'rmsprop',loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "model.fit(X,y,epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred=model.predict(X)\n",
    "\n",
    "b = np.zeros_like(y_pred)\n",
    "b[np.arange(len(y_pred)), y_pred.argmax(1)] = 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 235\n",
      "Trainable params: 235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() got an unexpected keyword argument 'outputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-4dcf45d2ce6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dense_5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/deeplearning/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'outputs'"
     ]
    }
   ],
   "source": [
    "mod = model(inputs=model.input,outputs=model.get_layer('dense_5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-8142f26ad089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y,b,labels=[\"0\", \"1\", \"2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 0]\n",
      " [1 0 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_train = np.array([(1,0,0), (1,0,0), (0,0,1), (1,0,0), (0,1,0)])\n",
    "y_pred = np.array([(1,0,0), (0,1,0), (0,0,1), (0,1,0), (1,0,0)])\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_train.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Inputs to hidden layer linear transformation\n",
    "        self.hidden = nn.Linear(4, 8)\n",
    "        # Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(8, 3)\n",
    "        \n",
    "        # Define sigmoid activation and softmax output \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj= Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2181, 0.2782, 0.5037],\n",
       "        [0.2243, 0.2710, 0.5047],\n",
       "        [0.2226, 0.2731, 0.5042],\n",
       "        [0.2261, 0.2705, 0.5034],\n",
       "        [0.2177, 0.2790, 0.5033],\n",
       "        [0.2160, 0.2827, 0.5013],\n",
       "        [0.2224, 0.2750, 0.5026],\n",
       "        [0.2204, 0.2762, 0.5034],\n",
       "        [0.2290, 0.2672, 0.5038],\n",
       "        [0.2237, 0.2718, 0.5045],\n",
       "        [0.2155, 0.2813, 0.5032],\n",
       "        [0.2224, 0.2749, 0.5027],\n",
       "        [0.2246, 0.2704, 0.5050],\n",
       "        [0.2256, 0.2691, 0.5054],\n",
       "        [0.2094, 0.2869, 0.5037],\n",
       "        [0.2095, 0.2895, 0.5010],\n",
       "        [0.2131, 0.2843, 0.5026],\n",
       "        [0.2184, 0.2783, 0.5033],\n",
       "        [0.2151, 0.2827, 0.5022],\n",
       "        [0.2165, 0.2813, 0.5022],\n",
       "        [0.2198, 0.2770, 0.5033],\n",
       "        [0.2177, 0.2803, 0.5020],\n",
       "        [0.2170, 0.2787, 0.5043],\n",
       "        [0.2236, 0.2748, 0.5016],\n",
       "        [0.2250, 0.2733, 0.5017],\n",
       "        [0.2254, 0.2706, 0.5040],\n",
       "        [0.2220, 0.2759, 0.5021],\n",
       "        [0.2183, 0.2782, 0.5035],\n",
       "        [0.2185, 0.2774, 0.5041],\n",
       "        [0.2252, 0.2719, 0.5030],\n",
       "        [0.2256, 0.2710, 0.5034],\n",
       "        [0.2189, 0.2780, 0.5031],\n",
       "        [0.2129, 0.2848, 0.5023],\n",
       "        [0.2104, 0.2873, 0.5023],\n",
       "        [0.2241, 0.2719, 0.5040],\n",
       "        [0.2200, 0.2748, 0.5052],\n",
       "        [0.2153, 0.2802, 0.5045],\n",
       "        [0.2179, 0.2785, 0.5036],\n",
       "        [0.2269, 0.2690, 0.5041],\n",
       "        [0.2198, 0.2766, 0.5036],\n",
       "        [0.2182, 0.2783, 0.5035],\n",
       "        [0.2354, 0.2594, 0.5052],\n",
       "        [0.2246, 0.2718, 0.5036],\n",
       "        [0.2218, 0.2772, 0.5010],\n",
       "        [0.2200, 0.2795, 0.5005],\n",
       "        [0.2254, 0.2707, 0.5039],\n",
       "        [0.2169, 0.2808, 0.5023],\n",
       "        [0.2241, 0.2723, 0.5036],\n",
       "        [0.2160, 0.2809, 0.5031],\n",
       "        [0.2206, 0.2754, 0.5041],\n",
       "        [0.2451, 0.2618, 0.4931],\n",
       "        [0.2477, 0.2611, 0.4912],\n",
       "        [0.2492, 0.2590, 0.4918],\n",
       "        [0.2617, 0.2493, 0.4890],\n",
       "        [0.2530, 0.2562, 0.4908],\n",
       "        [0.2580, 0.2527, 0.4893],\n",
       "        [0.2497, 0.2604, 0.4899],\n",
       "        [0.2562, 0.2522, 0.4917],\n",
       "        [0.2502, 0.2573, 0.4925],\n",
       "        [0.2579, 0.2540, 0.4881],\n",
       "        [0.2641, 0.2454, 0.4905],\n",
       "        [0.2511, 0.2589, 0.4899],\n",
       "        [0.2571, 0.2496, 0.4934],\n",
       "        [0.2556, 0.2545, 0.4898],\n",
       "        [0.2476, 0.2605, 0.4919],\n",
       "        [0.2454, 0.2618, 0.4929],\n",
       "        [0.2570, 0.2552, 0.4878],\n",
       "        [0.2527, 0.2543, 0.4929],\n",
       "        [0.2631, 0.2482, 0.4887],\n",
       "        [0.2555, 0.2527, 0.4918],\n",
       "        [0.2562, 0.2574, 0.4864],\n",
       "        [0.2491, 0.2586, 0.4924],\n",
       "        [0.2621, 0.2493, 0.4885],\n",
       "        [0.2562, 0.2527, 0.4911],\n",
       "        [0.2486, 0.2588, 0.4926],\n",
       "        [0.2473, 0.2602, 0.4925],\n",
       "        [0.2524, 0.2557, 0.4919],\n",
       "        [0.2537, 0.2569, 0.4894],\n",
       "        [0.2548, 0.2559, 0.4893],\n",
       "        [0.2482, 0.2574, 0.4944],\n",
       "        [0.2568, 0.2516, 0.4916],\n",
       "        [0.2551, 0.2522, 0.4927],\n",
       "        [0.2514, 0.2565, 0.4922],\n",
       "        [0.2646, 0.2491, 0.4862],\n",
       "        [0.2588, 0.2543, 0.4869],\n",
       "        [0.2488, 0.2617, 0.4895],\n",
       "        [0.2487, 0.2597, 0.4916],\n",
       "        [0.2587, 0.2501, 0.4912],\n",
       "        [0.2516, 0.2579, 0.4905],\n",
       "        [0.2586, 0.2519, 0.4895],\n",
       "        [0.2612, 0.2497, 0.4891],\n",
       "        [0.2532, 0.2565, 0.4903],\n",
       "        [0.2539, 0.2544, 0.4917],\n",
       "        [0.2567, 0.2513, 0.4920],\n",
       "        [0.2570, 0.2534, 0.4896],\n",
       "        [0.2514, 0.2573, 0.4913],\n",
       "        [0.2532, 0.2564, 0.4904],\n",
       "        [0.2502, 0.2579, 0.4920],\n",
       "        [0.2498, 0.2570, 0.4932],\n",
       "        [0.2535, 0.2559, 0.4906],\n",
       "        [0.2667, 0.2538, 0.4796],\n",
       "        [0.2681, 0.2493, 0.4827],\n",
       "        [0.2606, 0.2533, 0.4860],\n",
       "        [0.2650, 0.2498, 0.4852],\n",
       "        [0.2655, 0.2518, 0.4827],\n",
       "        [0.2631, 0.2503, 0.4865],\n",
       "        [0.2733, 0.2461, 0.4806],\n",
       "        [0.2633, 0.2489, 0.4878],\n",
       "        [0.2694, 0.2453, 0.4853],\n",
       "        [0.2557, 0.2596, 0.4847],\n",
       "        [0.2550, 0.2583, 0.4867],\n",
       "        [0.2643, 0.2506, 0.4852],\n",
       "        [0.2593, 0.2549, 0.4858],\n",
       "        [0.2718, 0.2474, 0.4808],\n",
       "        [0.2694, 0.2520, 0.4786],\n",
       "        [0.2592, 0.2573, 0.4835],\n",
       "        [0.2607, 0.2526, 0.4867],\n",
       "        [0.2536, 0.2585, 0.4879],\n",
       "        [0.2715, 0.2450, 0.4835],\n",
       "        [0.2709, 0.2432, 0.4859],\n",
       "        [0.2586, 0.2566, 0.4848],\n",
       "        [0.2670, 0.2513, 0.4817],\n",
       "        [0.2657, 0.2473, 0.4869],\n",
       "        [0.2605, 0.2528, 0.4867],\n",
       "        [0.2582, 0.2562, 0.4856],\n",
       "        [0.2572, 0.2540, 0.4888],\n",
       "        [0.2589, 0.2543, 0.4868],\n",
       "        [0.2581, 0.2553, 0.4865],\n",
       "        [0.2669, 0.2502, 0.4829],\n",
       "        [0.2573, 0.2526, 0.4901],\n",
       "        [0.2621, 0.2501, 0.4878],\n",
       "        [0.2494, 0.2605, 0.4901],\n",
       "        [0.2673, 0.2506, 0.4821],\n",
       "        [0.2600, 0.2514, 0.4886],\n",
       "        [0.2700, 0.2435, 0.4865],\n",
       "        [0.2582, 0.2551, 0.4867],\n",
       "        [0.2609, 0.2571, 0.4820],\n",
       "        [0.2602, 0.2533, 0.4865],\n",
       "        [0.2580, 0.2556, 0.4864],\n",
       "        [0.2562, 0.2571, 0.4867],\n",
       "        [0.2612, 0.2558, 0.4830],\n",
       "        [0.2543, 0.2597, 0.4861],\n",
       "        [0.2681, 0.2493, 0.4827],\n",
       "        [0.2614, 0.2549, 0.4838],\n",
       "        [0.2600, 0.2574, 0.4826],\n",
       "        [0.2582, 0.2572, 0.4846],\n",
       "        [0.2650, 0.2500, 0.4850],\n",
       "        [0.2585, 0.2555, 0.4860],\n",
       "        [0.2593, 0.2578, 0.4828],\n",
       "        [0.2621, 0.2529, 0.4850]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=t.tensor(X,dtype = t.float32)\n",
    "obj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2472, 0.3430, 0.4098],\n",
      "        [0.2452, 0.3466, 0.4082],\n",
      "        [0.2487, 0.3425, 0.4089],\n",
      "        [0.2487, 0.3427, 0.4086],\n",
      "        [0.2489, 0.3409, 0.4102],\n",
      "        [0.2476, 0.3417, 0.4106],\n",
      "        [0.2513, 0.3395, 0.4093],\n",
      "        [0.2473, 0.3432, 0.4095],\n",
      "        [0.2491, 0.3430, 0.4079],\n",
      "        [0.2457, 0.3454, 0.4088],\n",
      "        [0.2459, 0.3436, 0.4105],\n",
      "        [0.2491, 0.3413, 0.4096],\n",
      "        [0.2460, 0.3455, 0.4085],\n",
      "        [0.2509, 0.3407, 0.4085],\n",
      "        [0.2447, 0.3439, 0.4113],\n",
      "        [0.2488, 0.3389, 0.4122],\n",
      "        [0.2479, 0.3416, 0.4105],\n",
      "        [0.2474, 0.3431, 0.4095],\n",
      "        [0.2439, 0.3456, 0.4105],\n",
      "        [0.2496, 0.3398, 0.4106],\n",
      "        [0.2434, 0.3470, 0.4095],\n",
      "        [0.2490, 0.3411, 0.4100],\n",
      "        [0.2530, 0.3370, 0.4101],\n",
      "        [0.2459, 0.3457, 0.4084],\n",
      "        [0.2497, 0.3395, 0.4108],\n",
      "        [0.2441, 0.3477, 0.4082],\n",
      "        [0.2475, 0.3435, 0.4090],\n",
      "        [0.2462, 0.3439, 0.4099],\n",
      "        [0.2455, 0.3450, 0.4095],\n",
      "        [0.2485, 0.3426, 0.4090],\n",
      "        [0.2467, 0.3447, 0.4086],\n",
      "        [0.2439, 0.3472, 0.4089],\n",
      "        [0.2507, 0.3371, 0.4121],\n",
      "        [0.2489, 0.3390, 0.4121],\n",
      "        [0.2459, 0.3456, 0.4086],\n",
      "        [0.2459, 0.3453, 0.4088],\n",
      "        [0.2436, 0.3467, 0.4097],\n",
      "        [0.2497, 0.3398, 0.4105],\n",
      "        [0.2499, 0.3419, 0.4082],\n",
      "        [0.2464, 0.3441, 0.4095],\n",
      "        [0.2484, 0.3421, 0.4095],\n",
      "        [0.2437, 0.3508, 0.4056],\n",
      "        [0.2515, 0.3396, 0.4089],\n",
      "        [0.2486, 0.3427, 0.4088],\n",
      "        [0.2503, 0.3381, 0.4116],\n",
      "        [0.2462, 0.3458, 0.4079],\n",
      "        [0.2494, 0.3397, 0.4109],\n",
      "        [0.2495, 0.3416, 0.4089],\n",
      "        [0.2468, 0.3427, 0.4105],\n",
      "        [0.2466, 0.3442, 0.4092],\n",
      "        [0.2365, 0.3432, 0.4203],\n",
      "        [0.2429, 0.3361, 0.4210],\n",
      "        [0.2378, 0.3407, 0.4215],\n",
      "        [0.2428, 0.3410, 0.4163],\n",
      "        [0.2386, 0.3422, 0.4192],\n",
      "        [0.2469, 0.3313, 0.4218],\n",
      "        [0.2460, 0.3308, 0.4233],\n",
      "        [0.2471, 0.3385, 0.4143],\n",
      "        [0.2378, 0.3425, 0.4196],\n",
      "        [0.2497, 0.3317, 0.4186],\n",
      "        [0.2438, 0.3457, 0.4104],\n",
      "        [0.2457, 0.3346, 0.4197],\n",
      "        [0.2359, 0.3523, 0.4118],\n",
      "        [0.2442, 0.3337, 0.4221],\n",
      "        [0.2454, 0.3384, 0.4162],\n",
      "        [0.2379, 0.3433, 0.4187],\n",
      "        [0.2504, 0.3268, 0.4229],\n",
      "        [0.2425, 0.3391, 0.4184],\n",
      "        [0.2373, 0.3506, 0.4120],\n",
      "        [0.2425, 0.3410, 0.4165],\n",
      "        [0.2506, 0.3248, 0.4246],\n",
      "        [0.2403, 0.3430, 0.4166],\n",
      "        [0.2398, 0.3414, 0.4187],\n",
      "        [0.2428, 0.3353, 0.4219],\n",
      "        [0.2389, 0.3429, 0.4182],\n",
      "        [0.2382, 0.3432, 0.4186],\n",
      "        [0.2357, 0.3447, 0.4196],\n",
      "        [0.2401, 0.3376, 0.4222],\n",
      "        [0.2448, 0.3342, 0.4209],\n",
      "        [0.2404, 0.3458, 0.4138],\n",
      "        [0.2424, 0.3420, 0.4156],\n",
      "        [0.2417, 0.3433, 0.4150],\n",
      "        [0.2422, 0.3411, 0.4167],\n",
      "        [0.2456, 0.3303, 0.4241],\n",
      "        [0.2528, 0.3241, 0.4230],\n",
      "        [0.2496, 0.3271, 0.4234],\n",
      "        [0.2393, 0.3398, 0.4208],\n",
      "        [0.2357, 0.3505, 0.4138],\n",
      "        [0.2483, 0.3314, 0.4203],\n",
      "        [0.2446, 0.3381, 0.4173],\n",
      "        [0.2468, 0.3324, 0.4209],\n",
      "        [0.2447, 0.3334, 0.4219],\n",
      "        [0.2417, 0.3414, 0.4168],\n",
      "        [0.2450, 0.3415, 0.4134],\n",
      "        [0.2460, 0.3346, 0.4195],\n",
      "        [0.2473, 0.3320, 0.4208],\n",
      "        [0.2466, 0.3333, 0.4201],\n",
      "        [0.2412, 0.3398, 0.4190],\n",
      "        [0.2447, 0.3434, 0.4118],\n",
      "        [0.2453, 0.3358, 0.4189],\n",
      "        [0.2546, 0.3204, 0.4251],\n",
      "        [0.2488, 0.3273, 0.4239],\n",
      "        [0.2400, 0.3332, 0.4268],\n",
      "        [0.2464, 0.3262, 0.4274],\n",
      "        [0.2468, 0.3252, 0.4280],\n",
      "        [0.2378, 0.3353, 0.4269],\n",
      "        [0.2557, 0.3266, 0.4177],\n",
      "        [0.2386, 0.3367, 0.4247],\n",
      "        [0.2410, 0.3419, 0.4170],\n",
      "        [0.2459, 0.3236, 0.4305],\n",
      "        [0.2453, 0.3303, 0.4244],\n",
      "        [0.2426, 0.3337, 0.4237],\n",
      "        [0.2419, 0.3331, 0.4250],\n",
      "        [0.2483, 0.3302, 0.4214],\n",
      "        [0.2517, 0.3275, 0.4208],\n",
      "        [0.2480, 0.3262, 0.4258],\n",
      "        [0.2446, 0.3289, 0.4265],\n",
      "        [0.2435, 0.3221, 0.4345],\n",
      "        [0.2371, 0.3464, 0.4165],\n",
      "        [0.2427, 0.3455, 0.4118],\n",
      "        [0.2438, 0.3293, 0.4269],\n",
      "        [0.2520, 0.3264, 0.4216],\n",
      "        [0.2363, 0.3427, 0.4210],\n",
      "        [0.2419, 0.3368, 0.4213],\n",
      "        [0.2465, 0.3252, 0.4284],\n",
      "        [0.2403, 0.3312, 0.4286],\n",
      "        [0.2436, 0.3350, 0.4215],\n",
      "        [0.2469, 0.3295, 0.4236],\n",
      "        [0.2451, 0.3287, 0.4262],\n",
      "        [0.2373, 0.3365, 0.4263],\n",
      "        [0.2360, 0.3414, 0.4225],\n",
      "        [0.2396, 0.3286, 0.4318],\n",
      "        [0.2454, 0.3286, 0.4260],\n",
      "        [0.2428, 0.3335, 0.4237],\n",
      "        [0.2467, 0.3331, 0.4202],\n",
      "        [0.2345, 0.3398, 0.4257],\n",
      "        [0.2527, 0.3215, 0.4258],\n",
      "        [0.2466, 0.3260, 0.4274],\n",
      "        [0.2477, 0.3291, 0.4232],\n",
      "        [0.2413, 0.3343, 0.4244],\n",
      "        [0.2451, 0.3287, 0.4263],\n",
      "        [0.2406, 0.3374, 0.4220],\n",
      "        [0.2488, 0.3273, 0.4239],\n",
      "        [0.2457, 0.3256, 0.4287],\n",
      "        [0.2475, 0.3247, 0.4277],\n",
      "        [0.2424, 0.3346, 0.4230],\n",
      "        [0.2410, 0.3391, 0.4198],\n",
      "        [0.2439, 0.3320, 0.4241],\n",
      "        [0.2529, 0.3218, 0.4253],\n",
      "        [0.2501, 0.3245, 0.4254]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_size = 4\n",
    "hidden_sizes = [8, 16]\n",
    "output_size = 3\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-79d205788237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \"\"\"\n\u001b[0;32m-> 1368\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "\n",
    "n=565\n",
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "print(digits.target[n])\n",
    "plt.matshow(digits.images[n]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 8, 8), (1797,))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images.shape,digits.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = digits.images\n",
    "target=digits.target.reshape(1797,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model\n",
    "import keras\n",
    "\n",
    "inputs = Input(shape=(8,8))\n",
    "output_1 = Dense(8,activation='relu')(inputs)\n",
    "output_2 = Dense(16,activation='relu')(output_1)\n",
    "prediction = Dense(10,activation='softmax')(output_2)\n",
    "model = Model(input=inputs, outputs = prediction)\n",
    "model.compile(optimizer = 'rmsprop',loss = 'sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
    "# model.fit(X,y,epochs=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 8, 8)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 8, 8)              72        \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 8, 16)             144       \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 8, 10)             170       \n",
      "=================================================================\n",
      "Total params: 386\n",
      "Trainable params: 386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_56 to have 3 dimensions, but got array with shape (1797, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-e9408ad18183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_56 to have 3 dimensions, but got array with shape (1797, 1)"
     ]
    }
   ],
   "source": [
    "model.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "*************\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "    print(\"///////////\")\n",
    "else:\n",
    "    print(x_train.shape[0])\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    print(\"*************\")\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding=\"valid\",\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-421b1edfd8b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"keywords\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"Polar bears,baloons,Beaches\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"limit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"print_urls\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m   \u001b[0;31m#creating list of arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/trantorchd.com/paritosh.yadav/img/\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#passing the arguments to the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#pr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google_images_download/google_images_download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, arguments)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;31m# if the calling file contains params directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_executor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                     \u001b[0mpaths_agg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/google_images_download/google_images_download.py\u001b[0m in \u001b[0;36mdownload_executor\u001b[0;34m(self, arguments)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;31m######Initialization and Validation of user arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keywords'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download   #importing the library\n",
    "\n",
    "response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "\n",
    "arguments = {\"keywords\":\"Polar bears,baloons,Beaches\",\"limit\":20,\"print_urls\":True}   #creating list of arguments\n",
    "paths = response.download(\"/home/trantorchd.com/paritosh.yadav/img/\")   #passing the arguments to the function\n",
    "print(paths)   #pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing important libraries \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D, Flatten\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (3,3) # size of filter for conv layer\n",
    "input_size = (128,128,3)\n",
    "\n",
    "model_vgg16 = Sequential()\n",
    "\n",
    "model_vgg16.add(Conv2D(filters = 64, kernel_size = size, padding = 'same',\n",
    "                      activation = 'relu',input_shape = input_size))\n",
    "model_vgg16.add(Conv2D(filters = 64, kernel_size = size, padding = 'same',\n",
    "                      activation = 'relu'))\n",
    "\n",
    "model_vgg16.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model_vgg16.add(Conv2D(filters = 128, kernel_size = size, padding = 'same',\n",
    "                      activation = 'relu'))\n",
    "model_vgg16.add(Conv2D(filters = 128, kernel_size = size, padding = 'same',\n",
    "                      activation = 'relu'))\n",
    "\n",
    "model_vgg16.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model_vgg16.add(Conv2D(filters = 256, kernel_size = size, padding = 'same',\n",
    "                      activation = 'relu'))\n",
    "\n",
    "\n",
    "model_vgg16.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model_vgg16.add(Conv2D(filters = 512, kernel_size = size, padding = 'same',\n",
    "                      activation = 'relu'))\n",
    "\n",
    "\n",
    "model_vgg16.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model_vgg16.add(Conv2D(filters = 512, kernel_size = size, padding = 'same',\n",
    "                      activation = 'relu'))\n",
    "\n",
    "model_vgg16.add(MaxPooling2D(pool_size = 2, strides = 2))\n",
    "\n",
    "model_vgg16.add(Flatten())\n",
    "\n",
    "model_vgg16.add(Dense(1024, activation = 'relu'))\n",
    "model_vgg16.add(Dense(1024, activation = 'relu'))\n",
    "\n",
    "model_vgg16.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 126, 126, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 63, 63, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 63, 63, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 63, 63, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 31, 31, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 31, 31, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 15, 15, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 15, 15, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 7, 7, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1024)              4719616   \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 9,865,537\n",
      "Trainable params: 9,865,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
